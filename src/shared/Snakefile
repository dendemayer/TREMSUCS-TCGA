#configfile: "config.yaml"
report: "report_src/workflow.rst"
import glob
import os
import pandas as pd

include: "../tcga_deseq/Snakefile"
include: "../tcga_metilene/Snakefile"

threshold_str = config['thresh']   # 'threshold_0_threshold_5_threshold_10_threshold_20'
OUTPUT_PATH = config['OUTPUT_PATH']
projects_str = config['projects_str']  # 'TCGA-CESC_TCGA-HNSC'
PROJECTS = projects_str.split('_')  # ['TCGA-CESC', 'TCGA-HNSC']
if len(PROJECTS) != 1:
    PROJECTS.append(projects_str)
pipelines = config['pipelines']  # ['DESeq2', 'metilene']
pipeline_str = '_'.join(pipelines)
drug_str = config['drug_str']
script_path = workflow.basedir  #  '/homes/biertruck/gabor/phd/test_git_doc/tcga_piplines/src/shared'
# the script path will change depending on the main module we have acces from
# to it, but the scripts invoked here are always withing the shared dir, so go
# one dir up an reenter into shared (either from shared back into shared or
# metilene into shrared or deseq into shared:
script_path = os.path.join(script_path, os.path.pardir, 'shared')


rule download_helpfiles:
    """
    this rule will download the gdc_manifest and the gtf annotation file,
    md5checksum checks are performed
    """
    output:
        "{output_path}/metadata/{output_file}"
    conda:
        "envs/request.yaml"
    log:
        "{output_path}/logs/download_helpfiles/{output_file}.log"
    script:
        "scripts/download_help_files.py"

rule edit_annotation:
    """
    out of the provided annotation gtf, filter out the gene annotations with chr, start, ENSG, gene_type, gene_status, gene_name
    """
    input:
        annot_input = expand("{{output_path}}/metadata/{gtf_gz}", gtf_gz=config['gtf.gz']),
        script_file = os.path.join(script_path, "scripts/edit_annotation.py")
    output:
        annot_output = expand("{{output_path}}/metadata_processed/{gtf}_genes_transcripts.gz", gtf=config['gtf'])
    log:
        expand("{{output_path}}/logs/edit_annotation/{gtf}_annotated_genes.log", gtf=config['gtf'])
    conda:
        "envs/pandas.yaml"
    script:
        "scripts/edit_annotation.py"

#rule unzip_meta_files:
#    """
#    this is just necessary to overcome the problem of DAG resolving..
#    """
#    input:
#        "{output_path}/metadata/{output_file}.gz"
#    output:
#        "{output_path}/metadata/{output_file}"
#    conda:
#        "envs/gzip.yaml"
#    log:
#        "{output_path}/logs/download_helpfiles/{output_file}.log"
#    shell:
#        "gzip -dk {input}"

rule download_aux_files:
    """
    this rule loads the aux files for both pipelines:
    those are the 
    nationwidechildrens.org....
    files
    nationwidechildrens.org_auxiliary_cesc.txt
    # the same scrip like in download_data_files rule can be used, the output
    # path is different
    """
    input:
        expand("{{output_path}}/metadata/{manifest}", manifest=config['manifest_file'])
    output:
        "{output_path}/{project}/aux_files/{output_file}"
    conda:
        "envs/pandas.yaml"
    log:
        "{output_path}/{project}/logs/download_aux_files/{output_file}.log"
    script:
        "scripts/download_data_files.py"

rule download_data_files:
    """
    datafiles loaded via script
    """
    input:
        expand("{{output_path}}/metadata/{manifest}", manifest=config['manifest_file'])
    output:
        "{output_path}/{project}/{pipeline}/data_files/{output_file}"
    conda:
        "envs/pandas.yaml"
    log:
        "{output_path}/{project}/{pipeline}/logs/download_data_files/{output_file}.log"
    script:
        "scripts/download_data_files.py"

def get_aliquot_table(wildcards):
    proj_suffix = wildcards[1].split('-')[1].lower()
    OUTPUT_PATH = wildcards[0]
    project = wildcards[1]
    #pipeline = wildcards[2] # not needed in input
    suppl_2 = f'{OUTPUT_PATH}/{project}/aux_files/nationwidechildrens.org_biospecimen_aliquot_{proj_suffix}.txt'
    suppl_3 = f'{OUTPUT_PATH}/{project}/aux_files/nationwidechildrens.org_clinical_drug_{proj_suffix}.txt'
    suppl_4 = f'{OUTPUT_PATH}/{project}/aux_files/nationwidechildrens.org_clinical_patient_{proj_suffix}.txt'
    # IMPORTANT they are not working clinical tables in the repo, (just
    # concerning CESC) ,the right ones are those:
    # nationwidechildrens.org_clinical_patient_cesc.txt_1
    # nationwidechildrens.org_clinical_follow_up_v4.0_cesc.txt_1 for now just
    # overwrite the first loaded file with the new one (that are those where 2
    # diff filenames are given for one specific uuid
    DF_temp = pd.read_table(os.path.join(OUTPUT_PATH, 'metadata', config['manifest_file'][0]))
    DF_temp = DF_temp[DF_temp['filename'].str.contains(f'nationwidechildrens.org_clinical_follow_up_v.*_{proj_suffix}.txt')]['filename']
    follow_up_table = DF_temp[~DF_temp.str.contains('nte')].sort_values(ascending=False).iloc[0]
    suppl_5 = f'{OUTPUT_PATH}/{project}/aux_files/{follow_up_table}'
    suppl_6 = f'{OUTPUT_PATH}/{project}/aux_files/nationwidechildrens.org_biospecimen_sample_{proj_suffix}.txt'
    final_list = [suppl_2, suppl_3, suppl_4, suppl_5, suppl_6]
    return final_list

rule merge_meta_tables:
    """
    merging meta files to connect case id with the datafiles
    here is also the cutoff applied
    """
    input:
        expand("{script_path}/resources/GCv36_Manifests/{{project}}.tsv", script_path=script_path),
        get_aliquot_table,  # input[1-5]
        expand("{{output_path}}/metadata/{manifest}", manifest=config['manifest_file']), # input[0]
        os.path.join(script_path, "scripts/create_merged_tables.py"),
    output:
        #"{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/merged_meta_tables.tsv",
        "{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined.tsv"
    conda:
        "envs/pandas.yaml"
    wildcard_constraints: # important to just match singleproject patterns
        project = "[A-Z]*-[A-Z]*"
    log:
        "{output_path}/{project}/{pipeline}/logs/merge_meta_tables/{cutoff}.log"
    script:
        "scripts/create_merged_tables.py"

def get_multi_proj_drug_merge_tables(wildcards):
    """
    # to create the aggregated meta table over all projects, return the single project meta tables:
    wildcard structure like:
    ['/scr/dings/PEVO/NEW_downloads_3/TCGA-pipelines', 'TCGA-CESC_TCGA-HNSC',
    'carboplatn,paclitaxel_cisplatin', 'male', 'cutoff_0', 'threshold_0']
    we need every single proj merged table:
    "{output_path}/{project}/metilene/merged_meta_files/meta_info_druglist_merged_drugs_combined.tsv"
    """
    final_list = []
    projects = wildcards[1].split('_')
    for project in projects:
        final_list.append(
                os.path.join(wildcards[0], project, wildcards[2], 'merged_meta_files', wildcards[3], 'meta_info_druglist_merged_drugs_combined.tsv')) 
    return final_list

rule merge_meta_tables_multiproj:
    """
    take the single project meta_info_druglist_merged_drugs_combined.tsv  and
    concat them in multiproj dirs
    """
    input:
        get_multi_proj_drug_merge_tables
    output:
        "{output_path}/{projects}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined.tsv"
    wildcard_constraints: # make clear, that we want to include here multiproj
        projects = "[A-Z]*-[A-Z]*_.*"
    conda:
        "envs/pandas.yaml"
    log:
        "{output_path}/{projects}/{pipeline}/logs/merge_meta_tables_multiproj/{cutoff}.log"
    script:
        "scripts/create_merged_tables_multi.py"
    # not possible to invoke the conda env with the run statement
    #run:
    #    import pandas as pd
    #    pd.concat([pd.read_table(i) for i in input]).to_csv(output[0], sep='\t', index=False)

rule create_patient_plots:
    """
    based on the meta table (single project with rule merge_meta_tables and
    multi proj with rule merge_meta_tables_multiproj) make plots of the
    patients invoked, their survivaldata an age:
    /scr/palinca/gabor/TCGA-pipeline_5/TCGA-CESC_TCGA-HNSC/metilene/merged_meta_files/cutoff_0/
    """
    input:
        meta_table = "{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined.tsv",
        script_file = os.path.join(script_path, "scripts/create_patient_plots.py")
    output:
        final_pdf = report("{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_final.pdf", category="{pipeline}", subcategory="{project}", labels={"Category": "patient_overview", "cutoff": "{cutoff}", "type": "pdf"}),
        plot_file_age = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_age.pdf',
        plot_file_age_in_therapy = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_age_in_therapy.pdf',
        plot_file_age_not_in_therapy = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_age_not_in_therapy.pdf',
        plot_file_survival = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_survival.pdf',
        plot_file_survival_in_therapy = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_survival_in_therapy.pdf',
        plot_file_survival_not_in_therapy = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_survival_not_in_therapy.pdf',
        out_md_vital = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_vital.md',
        out_pdf_vital = '{output_path}/{project}/{pipeline}/merged_meta_files/{cutoff}/meta_info_druglist_merged_drugs_combined_vital.pdf',
    conda:
        "envs/pandas_pypdf_seaborn.yaml"
    log:
        "{output_path}/{project}/{pipeline}/logs/create_patient_overview/{cutoff}.log"
    params:
        drug_str = drug_str,
    script:
        "scripts/create_patient_plots.py"

rule plot_diffs:
    """
    for every found ensg or start of a DMR, plot the pval or the life mean
    diff, also together, if applied, with the different thresholds invoked
    """
    input:
        lifeline_aggregated = expand("{{output_path}}/{{project}}/{{pipeline}}/{{pipeline}}_output/{{drug_combi}}/{{gender}}/{{cutoff}}/{threshold_str}/{{pipeline}}_lifelines_aggregated.tsv.gz", threshold_str=threshold_str),
        script_file = os.path.join(script_path, "scripts/plot_thresh_diff.py")
    output:
        plot_diffs = report(expand("{{output_path}}/{{project}}/{{pipeline}}/{{pipeline}}_output/{{drug_combi}}/{{gender}}/{{cutoff}}/{threshold_str}/{{pipeline}}_plot_diffs_{{plot_type}}-{{count_type}}.pdf", threshold_str=threshold_str), category="{pipeline}", subcategory = "{project}", labels={"Category" : "lifeline_differences", "sex": "{gender}", "cutoff": "{cutoff}", "type": "pdf"}),
        plot_diffs_table = expand("{{output_path}}/{{project}}/{{pipeline}}/{{pipeline}}_output/{{drug_combi}}/{{gender}}/{{cutoff}}/{threshold_str}/{{pipeline}}_plot_diffs_{{plot_type}}-{{count_type}}.tsv.gz", threshold_str=threshold_str),
    conda:
        "envs/seab_matplot_plotl.yaml"
    threads:
        1
    log:
        "{output_path}/{project}/{pipeline}/logs/plot_diffs/{drug_combi}_{gender}_{cutoff}_{plot_type}_{count_type}.log",
    script:
        "scripts/plot_thresh_diff.py"

rule plot_diffs_eval:
    """
    for every found ensg or start of a DMR, plot the pval or the life mean
    diff, also together, if applied, with the different thresholds invoked
    -> just for the evaluated features (scored ones)
    -> the evaluated tables are also called lifeline_aggregated in the input to
    keep reusability of the same script
    """
    input:
        lifeline_aggregated = expand("{{output_path}}/{{project}}/{{pipeline}}/{{pipeline}}_output/{{drug_combi}}/{{gender}}/{{cutoff}}/{threshold_str}/{{pipeline}}_lifelines_evaluated-{{count_type}}.tsv.gz", threshold_str=threshold_str),
        script_file = os.path.join(script_path, "scripts/plot_thresh_diff.py")
    output:
        plot_diffs = report(expand("{{output_path}}/{{project}}/{{pipeline}}/{{pipeline}}_output/{{drug_combi}}/{{gender}}/{{cutoff}}/{threshold_str}/{{pipeline}}_plot_eval_diffs_{{plot_type}}-{{count_type}}.pdf", threshold_str=threshold_str), category="{pipeline}", subcategory= "{project}", labels={"Category": "lifeline_differences_evaluated", "sex": "{gender}", "cutoff": "{cutoff}", "type": "pdf"}),
        plot_diffs_table = expand("{{output_path}}/{{project}}/{{pipeline}}/{{pipeline}}_output/{{drug_combi}}/{{gender}}/{{cutoff}}/{threshold_str}/{{pipeline}}_plot_eval_diffs_{{plot_type}}-{{count_type}}.tsv.gz", threshold_str=threshold_str),
    conda:
        "envs/seab_matplot_plotl.yaml"
    threads:
        1
    log:
        "{output_path}/{project}/{pipeline}/logs/plot_diffs_eval/{drug_combi}_{gender}_{cutoff}_{plot_type}_{count_type}.log",
    script:
        "scripts/plot_thresh_diff.py"

def get_eval_input(wildcards):
    """
    returning all input files needed to create f.e.: 
    /scr/palinca/gabor/TCGA-pipeline_5/TCGA-CESC_TCGA-HNSC/DESeq2_metilene/carboplatin_carboplatin,paclitaxel_cisplatin/final_majority_vote.tsv
    """
    #(Pdb) [ i for i in wildcards.items()]
    #[('output_path', '/scr/palinca/gabor/TCGA-pipeline_5'), ('project', 'TCGA-CESC_TCGA-HNSC'), ('pipeline_str', 'DESeq2_metilene'), ('drug_str', 'carboplatin_carboplatin,paclitaxel_cisplatin')]
    output_path = wildcards.output_path
    projects_str = wildcards.project
    pipeline_str = wildcards.pipeline_str
    drug_str = wildcards.drug_str
    cutoffs = config['cutoffs']  # [0, 5, 8]
    cutoff_strs = ['cutoff_' + str(i) for i in cutoffs]  # ['cutoff_0', 'cutoff_5', 'cutoff_8']
    types = config['types']  # ['norm_counts', 'beta_vals']
    # requesting.
    #/scr/palinca/gabor/TCGA-pipeline_5/TCGA-CESC_TCGA-HNSC/DESeq2_metilene/carboplatin_carboplatin,paclitaxel_cisplatin/final_majority_vote.tsv
    # invoking f.e.:
    #/scr/palinca/gabor/TCGA-pipeline_5/TCGA-CESC_TCGA-HNSC/metilene/metilene_output/carboplatin,paclitaxel_cisplatin/female/cutoff_0/threshold_0_threshold_5_threshold_10_threshold_20/metilene_lifelines_evaluated-beta_vals.tsv.gz
    #/scr/palinca/gabor/TCGA-pipeline_5/TCGA-CESC_TCGA-HNSC/DESeq2/DESeq2_output/carboplatin,paclitaxel_cisplatin/female/cutoff_0/threshold_0_threshold_5_threshold_10_threshold_20/DESeq2_lifelines_evaluated-norm_count.tsv.gz
    evaluated_tables = []
    for pipeline, type_  in zip(pipelines, types):
        for project in PROJECTS:
            for gender in ['female', 'male', 'female_male']:
                for cutoff in cutoff_strs:
                    evaluated_tables.append(os.path.join(output_path, project, pipeline, f'{pipeline}_output', drug_str, gender, cutoff, threshold_str, f'{pipeline}_lifelines_evaluated-{type_}.tsv.gz' ))
    return evaluated_tables

rule majority_vote_all:
    """
    over the applied pipelines, aggregate every found outcome, make a majority
    vote which genesymbols are found the most over the configuration of the
    pipeline call
    for every deseq ensg we have the genesymbol available, not necessarily
    for every ENSG/ENST the genesymbol for metilene output -> fallback
    solution: use the DMR where the respective start is from, different
    starts of the same DMR are then aggregated (evantually a intersection is
    then needed)
    -
    to be able to aggregate over both, or one of both tables, the input
    function is not devided into the pipelines, the separation is then
    performed within the script if needed
    """
    input:
        evaluated_tables = get_eval_input,
        annot = expand("{{output_path}}/metadata_processed/{gtf}_genes_transcripts.gz", gtf=config['gtf']),
        HM450_annot = os.path.join(script_path, os.path.pardir,'tcga_metilene', 'resources', 'HM450.hg38.manifest.gencode.v36.tsv.gz'),
        script_file = os.path.join(script_path, "scripts/majority_vote_all.py")
    output:
        major_table =  report('{output_path}/{project}/{pipeline_str}/{drug_str}/final_majority_vote.tsv.gz', category="{pipeline_str}_table", subcategory="final_majority_vote", labels={"Pipelines:": "{pipeline_str}", "type": "table"}),
        venn_project = '{output_path}/{project}/{pipeline_str}/{drug_str}/final_majority_vote_venn_projects.pdf',
        venn_pipeline = '{output_path}/{project}/{pipeline_str}/{drug_str}/final_majority_vote_venn_pipeline.pdf',
        md_aggr =  '{output_path}/{project}/{pipeline_str}/{drug_str}/final_majority_vote_pipeline_project.md',
        pdf_aggr =  '{output_path}/{project}/{pipeline_str}/{drug_str}/final_majority_vote_pipeline_project.pdf',
        pdf_final =  report('{output_path}/{project}/{pipeline_str}/{drug_str}/final_majority_vote_pipeline_project_final.pdf', category="{pipeline_str}_plot", subcategory="final_majority_vote", labels={"Pipelines:": "{pipeline_str}", "type": "pdf"}),
        #major_table =  expand('{{output_path}}/{{project}}/{{pipeline_str}}/{{drug_str}}/final_majority_vote.tsv.gz', output_path=OUTPUT_PATH, project=PROJECTS[-1], pipeline_str=pipeline_str, drug_str=drug_str),
        #venn_project = expand('{{output_path}}/{{project}}/{{pipeline_str}}/{{drug_str}}/final_majority_vote_venn_projects.pdf', output_path=OUTPUT_PATH, project=PROJECTS[-1], pipeline_str=pipeline_str, drug_str=drug_str),
        #venn_pipeline = expand('{{output_path}}/{{project}}/{{pipeline_str}}/{{drug_str}}/final_majority_vote_venn_pipeline.pdf', output_path=OUTPUT_PATH, project=PROJECTS[-1], pipeline_str=pipeline_str, drug_str=drug_str),
        #md_aggr =  expand('{{output_path}}/{{project}}/{{pipeline_str}}/{{drug_str}}/final_majority_vote_pipeline_project.md', output_path=OUTPUT_PATH, project=PROJECTS[-1], pipeline_str=pipeline_str, drug_str=drug_str),
        #pdf_aggr =  expand('{{output_path}}/{{project}}/{{pipeline_str}}/{{drug_str}}/final_majority_vote_pipeline_project.pdf', output_path=OUTPUT_PATH, project=PROJECTS[-1], pipeline_str=pipeline_str, drug_str=drug_str),
        #pdf_final =  report(expand('{{output_path}}/{{project}}/{{pipeline_str}}/{{drug_str}}/final_majority_vote_pipeline_project_final.pdf', output_path=OUTPUT_PATH, project=PROJECTS[-1], pipeline_str=pipeline_str, drug_str=drug_str), category="pipeline_str", subcategory="" ),
    conda:
        "envs/pybedtools_matpl_seaborn.yaml"
    threads:
        1
    log:
        "{output_path}/{project}/{pipeline_str}/logs/majority_vote_all/{drug_str}.log",
        #expand("{{output_path}}/{{project}}/{{pipeline_str}}/logs/majority_vote_all/{{drug_str}}.log",output_path=OUTPUT_PATH, project=PROJECTS[-1], pipeline_str=pipeline_str, drug_str=drug_str)
    script:
        "scripts/majority_vote_all.py"

